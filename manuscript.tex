\begin{abstract}
\noindent
Identifying protein sequences with common ancestry is a core task in bioinformatics and evolutionary biology. However, methods for inferring and aligning such sequences in annotated genomes have not kept pace with the increasing scale and complexity of the available data. Thus, in this work we implemented several improvements to the traditional methodology that more fully leverage the redundancy of closely related genomes and the organization of their annotations. Two highlights include the application of the more flexible \textit{k}-clique percolation algorithm for identifying clusters of orthologous proteins and the development of a novel technique for removing poorly supported regions of alignments with a phylogenetic HMM. In making the latter, we wrote a fully documented Python package Homomorph that implements standard HMM algorithms and created a set of tutorials to promote its use by a wide audience. We applied the resulting pipeline to a set of 33 annotated \textit{Drosophila} genomes, generating 22,813 orthologous groups and 8,566 high-quality alignments.
\end{abstract}

\section{Introduction}
Comparative genomics is a powerful tool for yielding insights into evolutionary relationships, molecular function, and the forces that drive gene, genome, and population evolution. These methods often rely on the identification of homologous sequences or homologs, that is sequences with common ancestry, since this ensures that differences between sequences reflect variations in evolution from a common point of divergence. However, many analyses impose the additional condition that the sequences have diverged through speciation events (orthology) rather than duplications (paralogy) or other mechanisms such as horizontal gene transfer~\cite{Fitch1970}. The underlying assumption is orthologs have conserved equivalent functions whereas paralogs, by virtue of their redundancy, are more likely to diverge~\cite{Ohno1970, Nowak1997, Altenhoff2012, Pegueroles2013, Soria2014}.\footnote{For multiple sequences, orthology is usually defined relative to their most recent common ancestor. This technically includes sequences which split by duplication after this point (in-paralogs), but excludes sequences which split by duplication before (out-paralogs) \cite{Remm2001}. Many current orthology inference pipelines explicitly incorporate steps to detect in-paralogs. However, the resulting orthologs groups can easily be restricted to those without in-paralogs (single copy orthologs) for analyses where an assumption of conserved function is necessary.} This relationship between orthology and function is an essential component of modern biological research since it permits the transfer of annotations between biological systems using sequence similarity alone.

Given this importance, methods for inferring orthologous groups of proteins were developed shortly after the first genomes were sequenced in the late 1990s~\cite{Fleischmann1995, Goffeau1996, CESC1998}. One early and influential approach was to cluster triangles of hits resulting from homology searches between pairs of genomes~\cite{Tatusov1997}. Graph-based approaches have remained popular, and in the intervening years many other researchers have refined this method by implementing various pre- and post-processing steps. Despite these improvements, many databases and pipelines use the same triangle clustering algorithm~\cite{Jensen2007} or other methods which require relatively few hits between sequences to infer an orthologous group, \textit{e.g.} connected components and other single-linkage criteria~\cite{Remm2001, Train2017, Linard2011, Cosentino2018} or Markov clustering~\cite{Enright2002, Li2003, Emms2015}. However, the scale of biological sequence data has changed dramatically. For example, in the last decade, the number of annotated genomes available from NCBI has increased nearly 20-fold and currently exceeds 900 (Fig.~\ref{sfig:ncbi}). Though this figure is only a rough proxy of the total number of assemblies available, it will likely continue to grow rapidly in the coming years as many large-scale genome assembly efforts such as i5K~\cite{Thomas2020}, the Bird 10,000 Genomes Project~\cite{Feng2020}, and the Vertebrate Genomes Project~\cite{Rhie2021} have already yielded results. Thus, the dense taxonomic sampling made possible by these projects poses new challenges and opportunities for the standard methods of orthology inference and alignment, which implicitly assume fewer and more distantly related genomes or fail to fully leverage the redundancy and organization of their annotations.

In this work we therefore developed a computational pipeline that can robustly infer and align orthologous groups of proteins even when the genomes are highly redundant. Like many other orthology inference pipelines, our overall approach is based on clustering a graph of hits from homology searches. However, we modified many details to maximize the detection of highly diverged orthologs while also minimizing the impact of incomplete or incorrect annotations. Furthermore, since modern genome annotation pipelines frequently produce gene models and protein sequences in tandem, we implemented an additional clustering step to organize the resulting orthologous groups of proteins into gene-level units. However, most of our efforts were focused on the final step of aligning the orthologous sequences. Though genome annotation pipelines are often proficient at identifying the overall locus of genes, the accurate identification of exon boundaries and start codons when transcript evidence is limited remains an ongoing challenge~\cite{Frankish2015, Dunne2018}. Consequently, protein sequences derived from annotation pipelines can include non-homologous segments of significant length or exclude highly conserved segments. Such heterogeneity in the structure and length of the sequences in an orthologous group poses many challenges for their alignment and subsequent analysis. Thus, we implemented several novel quality control and data cleaning steps to correct mis-alignments and identify likely sequencing, assembly, or annotation errors.

To develop these methods, we chose a set of 33 assembled and annotated \textit{Drosophila} genomes, which includes all 12 species from the original \textit{Drosophila} 12 Genomes Consortium~\cite{D12GC2007}. However, the genomes of these 12 species have been re-sequenced since their first release, which has resulted in substantial improvements in their assemblies and annotations~\cite{Yang2018, Miller2018}. Despite these developments and other several other recent genome assembly projects of species in the \textit{Drosophila} genus, there is not yet a collection of high-quality alignments of orthologous proteins that reflects these improvements in genome assembly and diversity~\cite{Kim2021}. Given the \textit{Drosophila} genus spans diverse habitats and over 50 million years of evolution but maintains a conserved life cycle and body plan, such a resource would facilitate a new generation of studies that illuminate the forces that drive protein evolution in unprecedented detail~\cite{Wiegmann2011, Obbard2012}.

\begin{figure}[h!]
\includegraphics[width=\textwidth]{graphical_overview/out/graphical_overview.png}
\centering
\caption{\textbf{Overview of orthology inference pipeline.}
\textbf{(A-C)} The large, open circles represent the annotated genomes, and the small, filled circles represent the protein sequences associated with each annotation. Sequences that share homology are colored with shades of the same hue. \textbf{(D-F)} The small, filled circles and lines represent the same sequences and best hits from the previous steps.}
\label{fig:graphical_overview}
\end{figure}

\section{Results}
\subsection{Pipeline overview}
Our pipeline follows a similar overall approach to other graph-based methods of orthology inference. First, protein sequences from annotated genomes are collected (Fig.~\ref{fig:graphical_overview}A), and homology searches are conducted between all query-target pairs of genomes (Fig.~\ref{fig:graphical_overview}B). The raw output from these homology searches is processed to yield best hits between pairs of sequences (Fig.~\ref{fig:graphical_overview}C). Next, the network of best hits is clustered into self-consistent orthologous groups (Fig.~\ref{fig:graphical_overview}D). Since genes can have multiplied associated isoforms, we then implemented a novel second clustering step where orthologous groups are grouped by their parent genes, which are represented by the two sets of clusters with warm and cool colors, respectively (Fig.~\ref{fig:graphical_overview}E). Finally, representative sequences in each orthologous group are aligned (Fig.~\ref{fig:graphical_overview}F). In the following sections, we discuss each of these and other steps which were omitted for clarity in greater detail.

\subsection{Input genomes and pre-processing}
All annotated genomes in the genus \textit{Drosophila} available in April 2022 were downloaded from NCBI's RefSeq database. The assemblies annotated by the NCBI eukaryotic genome annotation pipeline have passed several quality checks and all have supporting transcript evidence, so the annotations are generally highly complete~\cite{Thibaud-Nissen2013}. The \textit{D. miranda} annotation was excluded due to its unusual karyotype~\cite{Dobzhansky1935}. Other annotations were excluded after preliminary clustering showed a deficiency in the number of orthologous groups containing those genomes, indicating their annotations were less complete (data not shown). The \textit{D. melanogaster} annotation was downloaded from FlyBase~\cite{Gramates2022}. In total, the input data consists of 33 genomes, which are listed in Table~\ref{stable:genomes}. Many genes have transcripts that differ only in their UTRs, and as a result there are many duplicate protein sequences in the annotations. Though not strictly necessary, we removed the duplicates in our pipeline, which greatly reduced the computational burden of later steps.

\subsection{Extraction of best hits from BLAST output}
The protein sequences in each genome annotation were searched against each other in reciprocal pairs using BLAST, yielding a list of high-scoring segment pairs (HSPs) for each query-target pair~\cite{Camacho2009}. HSPs are local alignments, meaning they do not necessarily span the entire lengths of the query and target sequences. Consequently, the search algorithm may return multiple HSPs for each query-target pair if statistically significant regions of homology are separated by nonhomologous or poorly conserved regions. Though the most significant HSP is often used to represent all HSPs between a query-target pair, this approach can fail to rank the pairs by their overall significance if their alignments are broken into multiple HSPs. Furthermore, since query-target pairs were later filtered by the amount overlap between their sequences, it can also exclude pairs that pass the overlap threshold even if the most significant HSP alone does not. Thus, HSPs were merged into a single object called a hit. The best hits for each query were then taken as the highest-scoring hits that passed a minimum overlap criterion and were reciprocal between the query and target sequences.

\subsection{Clustering in orthologous groups}
The best hits between sequences are naturally visualized as a graph where sequences are nodes and best hits are edges between nodes. Two connected components, sets of nodes joined by a sequence of edges, are shown (Fig.~\ref{fig:components}A-B). The sequences in the first (Fig.~\ref{fig:components}A) all contain C2H2 zinc fingers, whereas the sequences in the second (Fig.~\ref{fig:components}B) are members of the Par-1 family of serine/threonine protein kinases. In both components, some sets of nodes have a high density of edges, forming distinct clusters, whereas other nodes are only sparsely connected to their neighbors. To better understand the structure of these two components, we calculated the number of sequences, unique genes, and unique species in each. The first has 385, 346, and 33 sequences, genes, and species, respectively, and the second has 222, 33, and 33 sequences, genes, and species, respectively. We then plotted the relationship between the number sequences and unique genes across all components to see if this pattern holds true generally (Fig.~\ref{fig:components}C). Two distinct trendlines are apparent. The first increases linearly with the number of sequences with a slope of one, indicating each sequence is generally associated with a unique gene. The second is constant with an intercept of 33, indicating the number of unique genes quickly saturates at the total number of genomes. Thus, there are generally two classes of components. The first is composed of many distinct genes, whereas the second is composed of many different isoforms of a single group of genes.

The diffuse networks observed in the first component class are likely the result of a combination of factors, including rapid evolution, gene duplication, and annotation errors. Regardless of their origin, these hits are not strong candidates for comparative analyses since an orthology relationship is supported by relatively few genome pairs. Instead, likely orthologs should consistently identify each other as best reciprocal hits across many genome pairs. The same is true of the hits in the second component class. Although the genes as a unit form a single orthologous group, sequences with few hits are likely non-conserved or tissue-specific isoforms. Thus, orthologous groups can be operationally defined as self-consistent clusters in the hit graph. However, sequence divergence or assembly and annotation errors may prevent a best reciprocal hit between orthologous sequences across all genome pairs. In fact, although the most common number of reciprocal hits is 32, one fewer than the total number of genomes, many sequences have fewer (Fig.~\ref{fig:components}D). Thus, the clustering method should require a high degree of self-consistency without demanding complete consensus.

\begin{figure}[h!]
\includegraphics[width=\textwidth]{components/out/0017-005F.png}
\centering
\caption{\textbf{Selected connected components of hit graph and summary statistics.}
\textbf{(A-B)} Two distinct connected components of the hit graph. Edges are colored by the value of their bit score. \textbf{(C)} Hexbin plot of the number of sequences and the number of unique genes in each component. \textbf{(D)} Histogram of number edges associated with each sequence, \textit{i.e.} the degree of each node. Only the lower 99th percentile of the distribution is shown.}
\label{fig:components}
\end{figure}

The identification of sets of densely connected nodes in graphs is known as community detection in network analysis. While many community detection algorithms are available, only some are commonly used in the context of orthology inference. One early method that remains popular is building clusters progressively by identifying nodes that form a triangle with at least two other nodes in the cluster~\cite{Tatusov1997, Jensen2007}. Other approaches include the MCL algorithm, which clusters graphs by simulating stochastic flow~\cite{Enright2002, Li2003, Emms2015}, and connected components or other single-linkage criteria~\cite{Remm2001, Linard2011, Train2017, Cosentino2018}. While these methods are robust when clustering hit graphs derived from smaller or more diverse sets of genomes, they are not suitable for the large number of closely related genomes in this work since they require relatively few edges to define a cluster. For example, the MCL algorithm and connected components method assign a node to a cluster as long as it has a single edge, and triangle clustering only requires two edges to two adjacent nodes.

However, connected components and triangle clustering are special cases of the more general \textit{k}-clique percolation algorithm where \textit{k} equals two and three, respectively. The clique percolation algorithm detects clusters by first identifying cliques, sets of nodes which are fully connected, of a specified size \textit{k} in the graph (Fig.~\ref{fig:percolation}A). Clusters are then taken as the connected components of an overlap graph where an edge exists between two cliques if they share \textit{k}-1 nodes in common. An intuitive way to visualize this algorithm is by ``rolling'' a clique of some size \textit{k} over the graph (Fig.~\ref{fig:percolation}B). More specifically, a cluster is initiated when a set of nodes which form a \textit{k}-clique is identified. The cluster expands by shifting the \textit{k}-clique to an adjacent \textit{k}-clique that shares \textit{k}-1 nodes in common with the current \textit{k}-clique. A cluster stops expanding when there are no adjacent \textit{k}-cliques, and the algorithm terminates when there are no \textit{k}-cliques which are not part of a cluster. The strength of this algorithm is its ability to exclude sparsely connected nodes from clusters with an easily tunable parameter \textit{k}. Higher values of \textit{k} require greater overlap between a candidate node and those already in the cluster and therefore produce tighter clusters at the cost of excluding more speculative orthology relationships (Fig.~\ref{fig:percolation}C). We set \textit{k} to four as compromise between these concerns, yielding 22,813 orthologous groups, a plurality of which contained all 33 species (Fig.~\ref{sfig:clusters}).

\begin{figure}[h!]
\includegraphics[width=\textwidth]{percolation/out/percolation.png}
\includegraphics[width=\textwidth]{percolation/out/005F.png}
\centering
\caption{\textbf{Clique percolation algorithm.}
\textbf{(A)} Cliques for \textit{k} equal to three, four, five, and six. \textit{k} equal to one and two correspond to a single node and two nodes joined by an edge, respectively. \textbf{(B)} Illustration of clique percolation algorithm where \textit{k = 4}. \textbf{(C)} A single component clustered by clique percolation with varying values of \textit{k}. Nodes are colored according to their cluster. If a node belongs to multiple clusters, it uses a blend of those colors.}
\label{fig:percolation}
\end{figure}

\subsection{Addition of paralogs to orthologous groups}
A weakness of the best reciprocal hits criterion is its exclusion of recently diverged paralogs. Since only the highest scoring hits for each query are included in the graph, a paralog without a corresponding duplicate in the target genome is ignored if it is marginally more diverged than the other copy. This is corrected by adding likely paralogs to the orthologous groups. Briefly, the protein sequences in each genome were searched against themselves. If the bit score for an intra-genome hit exceeded the bit score of any inter-genome hits for the same query, the two sequences were identified as a paralogous pair. Orthologous groups were then supplemented with paralogs by adding the paired sequences for each of the original members of the orthologous group. Most orthologous groups contain no paralogs, and those that do generally have few relative to the original number of sequences in the group (Fig.~\ref{sfig:paralogs}).

\subsection{Grouping orthologous groups by gene}
As genes can have several annotated isoforms, each gene can be associated with several orthologous groups. However, the orthologous groups are not organized into gene-level units since they were clustered using sequence similarity only. A graph-based approach was therefore used to group orthologous groups with similar sets of parent genes. First, a gene overlap graph was constructed by defining an edge between orthologous groups if the intersection of their associated sets of parent genes is at least 50\% of the smaller of the two. Gene groups were then taken as the connected components of the resulting graph, yielding 14,909 groups. This is commensurate with the roughly 15,000 genes in each genome, which suggests this approach has successfully clustered orthologous groups derived from a common set of parent genes.

\subsection{Initial alignment and selection of representative sequences}
Since the NCBI annotation pipeline incorporates transcriptome data from a variety of sources, its inputs are heterogeneous in sequencing depth, developmental stage, and tissue of origin across different genomes. As a result, some genomes are annotated with different or multiple splice isoforms of a given orthologous gene, which can create complex networks in the resulting hit graph. For example, if the genomes are variably annotated with one or both of two distinct isoforms, the resulting graph may contain two clusters connected by a ``bridge'' formed by the genomes which contain only one of the isoforms. If the nodes bridging the two clusters form cliques with themselves and the clusters, the clique percolation algorithm will merge all the nodes into a single orthologous group where some genes have multiple associated sequences. However, these additional sequences can complicate downstream comparative analyses that may not easily generalize to genes with multiple associated sequences. Thus, in our pipeline a single representative was chosen for each gene using an alignment-based strategy detailed in the methods section. Briefly, a statistical profile was created from an alignment of the sequences in each orthologous group, and the representative for each gene was chosen as the sequence which best matched this profile.

\subsection{Selection of single copy orthologous groups}
The criteria for selecting orthologous groups for further analyses depends on the biological question under investigation. For example, studies of gene duplication will focus on orthologous groups with paralogs in some lineages but not in others. In contrast, analyses which assume functional conservation should restrict the orthologous groups to single copy orthologs since paralogs more frequently undergo functional divergence~\cite{Altenhoff2012, Pegueroles2013, Soria2014}. A simple method for identifying such groups is requiring each species to have exactly one associated gene. However, since the probability of at least one missing gene annotation approaches one as the total number of genomes increases, this is too restrictive and fails to leverage the redundancy of closely related genomes. Instead, a set of phylogenetic diversity criteria detailed in Table~\ref{stable:diversity_criteria} were applied to ensure the major lineages were represented in downstream analyses. Furthermore, genome-wide analyses should select one orthologous group per each of the previously identified gene groups as to not bias the results towards genes with many distinct groups of isoforms. In summary, orthologous groups failing the phylogenetic diversity criteria were first removed, and the representative for each gene group was chosen as the highest scoring orthologous group when ranked by the number species and the sum of the bit scores associated with each edge. This significantly reduced the number of orthologous groups from 22,813 to 8,566.

\subsection{Alignment refinement}
Though the pipeline’s quality control measures ensure a high degree of overall sequence identity between members of an orthologous group, some sequences contain long ``poorly supported'' segments which have no homology to most or any other sequences in the alignment. Since most common multiple sequence alignment algorithms assume the sequences are largely homologous, these segments are sometimes ``over-aligned'' by forcing them into alignment where chance sequence similarities occur. Typically, these segments remain contiguous, so the alignments alternate between short runs of columns with few or no gaps and large gap-rich regions (Fig.~\ref{fig:realignment}A-B, left). More rarely, when long poorly supported segments are adjacent to a long gap in the same sequence, the two are interlaced, yielding long gaps interrupted by short segments of spurious alignment (Fig.~\ref{fig:realignment}C, left).

The aligner MAFFT has a mode for addressing over-alignment with a parameter, \textit{a\textsubscript{max}}, that adjusts the strength of the correction~\cite{Katoh2013, Katoh2016}. \textit{a\textsubscript{max}} varies between 0 and 1, with higher values yielding a stronger correction. While values above 0.8 completely eliminate over-alignment and successfully align highly conserved regions, the alignment as a whole is severely degraded, as even homologous sequences with a small amount of divergence are separated by gaps. Thus, in our pipeline orthologous groups were aligned in two stages. In the first, the sequences were aligned with a strong correction of 0.7. Highly conserved regions were identified, which divided the alignment into a complementary set of diverged regions. The sequences in each of these regions were extracted and aligned separately with a more conservative value for \textit{a\textsubscript{max}} of 0.4. The resulting ``sub-alignments'' were ``stitched'' back into their positions in the original alignment. By defining highly conserved ``anchor'' regions, this approach largely prevents the alignment of chance sequence similarities in long poorly supported segments (Fig.~\ref{fig:realignment}, right).

\begin{figure}[h!]
\includegraphics[width=\textwidth]{realignment/out/realignment.png}
\centering
\caption{\textbf{Alignment with long poorly supported segments.}
The alignments of representative sequences in orthologous groups 0167 \textbf{(A)}, 2770 \textbf{(B)}, and 23D9 \textbf{(C)} before and after refinement.}
\label{fig:realignment}
\end{figure}

\subsection{Alignment curation}
Although the refinement process corrects most cases of over-alignment, the alignment may still contain regions whose aligned segments have poor or inconsistent support. For example, long poorly supported segments in internal regions were not removed from the alignment since they are bounded by at least one consensus column to the left and right. Additionally, some regions have a significant fraction of sequences with strongly supported segments, but the observed gap pattern is discordant with the expected phylogenetic relationships. Since they are present in so few sequences, the former segments are likely artifactual, resulting from errors during assembly or annotation. (Biological explanations such as alternative splice sites, frameshift mutations, or transposition events are also possible, however.) In contrast, the high sequence identity and clear boundaries of the segments in the latter regions suggest they are conserved but skipped exons. Given the heterogeneous sourcing of the transcript evidence, these sequences containing these segments are likely splice isoforms specific to certain tissues or developmental stage.

% To investigate these hypotheses, the genome sequences and supporting transcript evidence for several segments and regions were examined in detail: 0254, 26CF, 202C, 188E, 2E9F, 34B7, 0C31.

Since the segments in these regions are likely the result of incorrect or incomplete annotations rather than meaningful biological variation, maintaining them in the alignments would propagate spurious homologies to subsequent analyses. This is a common issue in alignments generated by automated pipelines, so downstream analyses often focus on the strongly supported regions by removing or ``trimming'' columns below some threshold number of gaps or sequence identity~\cite{Castresana2000, CapellaGutierrez2009}. This approach, however, is inadequate if the taxonomic sampling is dense, as a single indel event along a lineage containing many species can increase the number of gaps above the threshold. Moreover, as this method does not incorporate any spatial information, it can rapidly alternate between trimming and preserving columns. Thus, it can severely disrupt any analyses which are sensitive to the spatial organization of an alignment.

Phylogenetic HMMs (phylo-HMMs) are statistical models that incorporate phylogenetic and spatial information to calculate the probability that each observation in a sequence was generated by one of several hidden states~\cite{Felsenstein1996, Siepel2004}. Since they can evaluate both the probability of a gap pattern in a column given the known phylogenetic relationships and the local context, a phylo-HMM was used to segment the alignment into contiguous regions with different patterns of gaps. A fully specified phylo-HMM requires a fixed number of hidden states and a probability distribution for each. Thus, we identified four distinct types of regions in the alignments, roughly corresponding to highly conserved regions with few to no gaps, diverged regions, regions with a stable gap pattern discordant with the expected phylogenetic relationships, and regions with poorly supported segments. For simplicity, however, we refer to the states that generate each type of region as 1A, 1B, 2, and 3, respectively. To model probability distributions for each state, we first conceptualized the observed alignments as the superposition of two distinct processes (Fig.~\ref{fig:hmm}A, left). The first is a phylogenetic process which evolves and splits a single ancestral sequence over time according to a tree. The second is the annotation process which can erroneously exclude or include segments from a sequence. The result is an alignment of annotated sequences which contains evolutionary information obscured by noise from the annotation process, shown here by the exclusion of three N-terminal residues in the fourth annotated sequence. To simplify modeling this behavior with an HMM, we coded the sequences into binary symbols. The distributions for each state then consisted of two components derived from the encoded sequences (Fig.~\ref{fig:hmm}A, right). The first component models the gap pattern with a Markov process. This Markov process is in turn composed of two subprocesses where the first is a phylogenetic process, and the second is a jump process. These subprocess roughly correspond to changes caused by evolution and annotation, respectively. Because this first component did not fully capture the propensity for the gap patterns to remain constant, we included a second component that models the ``gap stickiness'' as a beta-binomial random variable by counting the number of symbols that remain constant between columns. Each component is associated with a set of parameters, and the unique parameters for each state yield its characteristic gap pattern and gap stickiness.

After the model was trained on manually labeled examples, it was used to assign a label to the columns in each alignment. Columns assigned to states 1A and 1B are the regions of interest for downstream analyses since the gaps generally follow the expected pattern given the phylogenetic tree. In contrast, columns assigned to states 2 and 3 largely corresponded to the long poorly supported segments and phylogenetically discordant regions discussed previously and were therefore removed from the alignments. In the example decoded alignment shown, the decoded states closely follow the expected patterns (Fig.~\ref{fig:hmm}B). Overall, 29\% of alignments were trimmed of at least one segment or region. However, 87\% of the trims were segment trims, meaning the removed segments were largely inferred as state 3 and therefore were likely long poorly supported segments aligned to few if any other sequences (Fig.~\ref{sfig:insertion_trim}).

\begin{figure}[h!]
\includegraphics[width=\textwidth]{hmm/out/hmm_architecture.png}
\includegraphics[width=\textwidth]{hmm/out/2252.png}
\centering
\caption{\textbf{HMM emission architecture and a decoded alignment.}
\textbf{(A)} Schematic of theoretical alignment generating process and corresponding probabilistic components in HMM. White and colored boxes indicate gap and non-gap symbols in the biological sequences, respectively. White and grey boxes indicate gap and non-gap symbols in the encoded sequences, respectively. c\textsubscript{0} and c\textsubscript{1} indicate the first and second columns in the alignment, respectively. The parameters associated with each component are shown to the right. \textbf{(B)} The alignment of the representative sequences in orthologous group 2252 decoded using the trained HMM.}
\label{fig:hmm}
\end{figure}

Though the phylo-HMM removed phylogenetically incongruent insertions, some sequences still contained extensive segments of uninterrupted gaps. These segments are easily identified in regions which are otherwise highly conserved, so they are also likely the result of incorrect or incomplete annotations. However, they can also span more diverged regions, which complicates a simple rule- or threshold-based approach for identifying them. Thus, another phylo-HMM was trained to label each position in a sequence as generated by either a ``missing'' or ``not missing'' state. In this case, though, the aligned sequences were processed individually and not as aligned columns. As the previous phylo-HMM already ensured each column has sufficient support, these labels can instead be used to exclude sequences from downstream analyses depending on the amount of tolerated overlap with the regions of interest. Overall, 15\% of alignments have at least one sequence with a segment of ``missing'' data (Fig.~\ref{sfig:missing_trim}).

\subsection{Inference of species trees}
Many phylogenetic methods require a species tree to inform the evolutionary relationships between sequences. In fact, the phylo-HMMs discussed previously used a species tree as an input, though we omitted this detail for clarity of exposition. Therefore, to support the curation step and other downstream analyses, we sought to infer phylogenetic trees from the aligned sequences. However, since the roots of phylogenetic trees are not identifiable with commonly used time-reversible substitution models, we repeated the orthology inference pipeline with the outgroup species \textit{Scaptodrosophila lebanonensis}. Afterwards, we inferred phylogenetic trees using the LG model of amino acid substitution from 100 meta-alignments sampled from alignments of single copy orthologous groups. We then combined them into a single consensus tree (Fig.~\ref{fig:trees}A). To provide a similar tree for the analysis of non-coding regions, we inferred phylogenetic trees using the GTR model of nucleotide substitution from 100 meta-alignments sampled from nucleotide alignments which were ``reverse translated'' from the protein alignments and their corresponding coding sequences (\ref{fig:trees}B). Both trees have an identical topology, which is consistent with other published phylogenies~\cite{D12GC2007, DaLage2007}.

\begin{figure}[h!]
\includegraphics[width=\textwidth]{trees/out/trees1.png}
\centering
\caption{\textbf{Phylogenetic tree of species.}
\textbf{(A)} Consensus tree from LG model fit to meta-alignments directly sampled from the original protein alignments. \textbf{(B)} Consensus tree from GTR model fit to meta-alignments sampled from ``reverse translated'' nucleotide alignments. Values at nodes are bootstrap percentages.}
\label{fig:trees}
\end{figure}

\section{Discussion}
\subsection{Developments in genome assembly and annotation challenge existing methods of orthology inference}
The orthologous groups and alignments yielded by this pipeline are a valuable resource for comparative studies of gene birth/death processes and protein evolution at the level of both entire proteomes and specific gene families in the \textit{Drosophila} genus. To assist these efforts, the final alignments after curation and the labels from the ``missing'' phylo-HMM are provided as supplemental data. Although this work focused on single copy orthologs, other studies may require different subsets of orthologous groups that demand other pre-processing and alignment strategies. Therefore, we have included the orthologous groups and the initial alignments with and without non-representative sequences in the supplemental data as well. While we anticipate these resources will remain relevant in the near term, the trends that permitted this work to substantially improve on previous efforts will render them obsolete in the coming years as more \textit{Drosophila} genomes are assembled and annotated. However, an authoritative and lasting set of orthologous groups and alignments is not the primary goal of this work. Instead, it serves as a case study in how dense taxonomic sampling and modern genome assembly and annotation pipelines present new opportunities and challenges to the traditional techniques for identifying and aligning orthologous groups.

For example, despite many additional pre-processing steps and other tweaks introduced by later authors, the basic framework of orthology inference by clustering the hit graph has remained largely unchanged in the past twenty years~\cite{Tatusov1997, Remm2001, Li2003, Jensen2007, Linard2011, Emms2015, Train2017, Cosentino2018}. This longevity is a testament to the robustness of the underlying idea that orthologous proteins should consistently identify each other as the most similar pairs between their genomes. Even as the number of genomes and their taxonomic density has increased dramatically, many orthology inference pipelines continue to use algorithms which were originally applied to sets of far fewer and more distantly related genomes. This mismatch in scale increases the chance of propagating annotation errors since only a small number of edges are needed to create or merge clusters. Thus, we instead applied a generalization of the triangle and connected components clustering methods called \textit{k}-clique percolation where \textit{k} is a tunable parameter that influences the tightness of a cluster. The optimal value of \textit{k} for a given set of genomes is unclear and likely depends on the desired trade-off between sensitivity and specificity. Furthermore, \textit{k} is not necessarily a global parameter and can instead depend on the properties of each connected component. For example, one possibility is to take an entire component as an orthologous group if its number of unique genes and unique species are equal since all the sequences are isoforms of a single set of genes. This would effectively set \text{k} equal to one for this component. Another approach is to make \textit{k} an decreasing function of the density of edges, so sparser graphs are clustered more permissively. However, percolation theory or simulations may yield additional insights.

Another challenge is the annotation of multiple isoforms for a single gene. Though prior pipelines have generally selected the longest isoform as the representative before conducting the orthology searches, if the sequences do not share a common intron-exon structure this approach can introduce artifacts or other issues during alignment. Instead, as protein sequences are increasingly derived from or linked to genomic sequences, we sought to incorporate the full annotations into the orthology inference pipeline. This, however, created two additional complications. First, a single gene could have several associated orthologous groups if its isoforms belonged to different clusters. Second, a single orthologous group could have several isoforms of a single gene if its isoforms were clustered together. In both cases, the presence of multiple sequences for a single gene creates ambiguities over which is the ``primary'' isoform. Since the first occurs at the level of orthologous groups, the orthologous groups were first grouped by the similarity of their parent genes using a graph-based strategy. Afterwards, a single representative is easily chosen as the group with the largest number of distinct species, though other criteria are possible. Since the second occurs within an orthologous group, the sequences were first aligned, and a representative for each gene was chosen as the sequence which was most concordant with this initial alignment.

The second major innovation in this work is its method for the refinement and trimming of alignments. Since sequences produced from automated annotation pipelines can contain long segments which are not homologous to most or any other sequences in their respective orthologous groups, their alignments may contain over-aligned or poorly supported regions which can introduce artifacts into downstream analyses. Thus, in refinement over-alignment is avoided by aligning the sequences in two stages. In the first highly conserved regions are aligned using a strong correction for over-alignment, and in the second more diverged regions are aligned with a weaker correction. This process usually prevents errors caused by long poorly supported segments without degrading the quality of the alignment. In trimming, a phylo-HMM is used to remove regions which are poorly supported by the phylogenetic consensus.

\subsection{Comprehensive bioinformatic analyses of proteins will depend on splice-sensitive alignments}
While the combination of these two steps yielded high-quality alignments that are suitable for further analyses, they are an \textit{ad hoc} fix for underlying issues with the gene models and alignment algorithms. The most principled solution is to optimize or supplement the gene models using the initial alignments generated by the orthology inference pipeline, which is possible with tools such as OMGene or OrthoFiller~\cite{Dunne2018, Dunne2017}. However, if preserving the original annotations is desired or necessary, the remaining possibility is to correct the alignments as we have done here. In fact, the errors we sought to address broadly stem from shortcomings of current alignment algorithms rather than errors in the sequences themselves. Though the scoring functions of modern multiple sequence alignment algorithms are complex, they are generally derived from models that penalize gaps with a linear or affine cost. As a result, they often interlace gaps with short, aligned segments rather than a single long gap. However, when the sequences are different isoforms of a single gene, their alignment will necessarily contain contiguous exon sized gaps. The same is true when aligning isoforms of diverged orthologs, though the relationship between their exons may be complex.

The most popular aligners for protein sequences (Clustal Omega~\cite{Sievers2017}, MAFFT~\cite{Katoh2013}, MUSCLE~\cite{Edgar2004}, T-Coffee~\cite{Notredame2000}) do not include splice sites in their alignments, which makes them prone to aligning non-homologous exons. Current algorithms can easily be extended to incorporate splice sites by coding them as a new symbol and preventing alignment between splice sites and amino acids, which was recently implemented in the aligner, \textit{Mirage}~\cite{Nord2018}. The biggest challenge in practice, however, is mapping a protein sequence to its genomic sequence to identify splice sites in the protein sequence. Although this information can in principle be derived from the GTF annotation files produced by the NCBI pipeline, annotating the splice junctions in the protein sequences themselves would facilitate splice-sensitive alignment.

These improvements would enhance rather than replace the phylo-HMM trimming method developed in this work. The model could easily be extended to include a state that outputs a splice symbol before transitioning to one of the states in the current architecture. This intermediate state would increase the accuracy of state inference since a splice symbol followed by a phylogenetically discordant gap pattern would strongly signal a state 2 region. The association between state 2 and skipped exons can be made explicit by requiring that transitions to and from state 2 first proceed through the splice state. This of course depends on proper labeling of the training data, which would be trivial since the boundaries between exons would be marked by splice site symbols rather than inferred from gap patterns. Unfortunately, this would not allow the phylo-HMM to label extended exon boundaries as state 2 since they would not be bounded by splice symbols to the left and right. Accordingly, the phylo-HMM would need to permit transitions between state 3 and any other state to accommodate more complex splice variants and other annotation errors. Thus, this extended phylo-HMM would combine the strengths of splice-sensitive alignment with the more heuristic approach used here. Since state 2 inferences would necessarily correspond to skipped exons, they would be suitable for analyses of this form of alternative splicing. Though state 3 inferences would not directly correspond to specific biological process, they still have value as spatially and phylogenetically aware labels for trimming poorly supported segments from alignments.

The phylo-HMM could be further enhanced by expanding its emission distribution to include more symbols in the amino acid alphabet. This would allow it to better model observed substitution patterns between specific symbols, for example the high rate of exchange between gaps and glutamine residues caused by polyglutamine tracts. The transitions between amino acids could be parametrized with a published matrix such as LG~\cite{Le2008}, but the transitions between amino acids and gaps would be inferred from labeled data. It is unclear if the resulting gain in accuracy would justify the increased computational burden, however.

\subsection{Accessible computational tools will facilitate future comparative studies}
Though benchmarks are available for optimizing and comparing methods of orthology inference, the metrics are calculated over a set of reference genomes which are sparsely sampled over a broad taxonomic range, so it is unclear if they are informative for method designed to yield robust inferences when the genomes are highly related~\cite{Nevers2022}. Furthermore, the heterogeneity of genome architectures and annotations may require quality assurance methods tailored to each set of genomes. Thus, there is likely no one-size-fits-all approach to orthology inference, and with many other standalone programs available for more standard use cases (Hieranoid~\cite{Kaduk2017}, OMA standalone~\cite{Altenhoff2019}, OrthoFinder~\cite{Emms2019}, OrthoInspector~\cite{Linard2014}, Orthologer~\cite{Zdobnov2020}), we have chosen not to package the code into an end-to-end pipeline. Instead, we have devoted considerable attention to organizing and documenting the code to make it accessible to a newcomer and thereby facilitate the adaptation of specific steps to similar projects as needed.

In contrast, though many HMM packages are available for the Python programming language, we found none were satisfactorily documented or contained tutorials to introduce HMMs and their APIs to a wide audience. We therefore refactored this code into a package available on PyPI and GitHub called Homomorph. The package itself only implements standard HMM algorithms, but the GitHub repository includes tutorials that introduce the API and implement training routines. Similar tutorials for machine learning libraries such as TensorFlow have undoubtedly fueled the application of neural networks across diverse fields, but HMMs are also powerful models that can be more appropriate when the data obey certain statistical or structural constraints. Thus, we hope this package and its accompanying tutorials will serve as an on-ramp to HMMs and spur their greater adoption by non-specialists.

Though databases of orthologous groups such as COGs~\cite{Galperin2020}, Ensembl Compara~\cite{Herrero2016}, EggNOG~\cite{HuertaCepas2018}, OMA~\cite{Altenhoff2020}, OrthoDB~\cite{Zdobnov2020}, OrthoInspector~\cite{Nevers2018}, and OrthoMCL~\cite{Chen2006} will continue to be useful for comparative studies across broad taxonomic ranges, the increasing speed at which high-quality genome assemblies and annotations are produced means no single database can encompass the most complete data. Furthermore, since many early comparative genomics studies spanned diverse branches of the tree of life, future research will likely prioritize taxonomic depth over breadth. Thus, custom sets of orthologous groups will grow more and not less common. Despite the challenges these developments pose, they also present new opportunities to bridge the gap between mutational and macroevolutionary processes.

\section{Materials and methods}
\subsection{Sequence de-duplication and BLAST search parameters}
The protein sequences for each annotation were de-duplicated by removing any sequences which had already appeared in association with the same gene. Thus, the first accession associated with a sequence and gene pair was the sequence’s representative accession for the gene. BLAST+ 2.13.0 was used for the sequence similarity searches~\cite{Camacho2009}. An E-value cutoff of 1 was used for the initial searches. However, this cutoff was lowered to 1E-10 during processing of the BLAST output.

\subsection{Extraction of HSPs from BLAST output}
To reduce the computational burden of merging HSPs into hits, the BLAST output was filtered to extract HSPs associated with the highest-scoring gene. The HSPs were first grouped by target protein, and the resulting groups were sorted in descending order by the bit score of their highest-scoring HSP. Iterating over the groups, all HSPs in a group were passed to the next step until the parent gene of the group was not the parent gene of the highest ranked group. This method collected all candidate HSPs for a target gene if the highest-scoring HSP within a group exceeded the highest-scoring HSP of the next best gene. This is in some senses an extension of the best hit criterion where hits are considered at the level of genes rather than proteins. If multiple genes tied for the highest-scoring HSP, the iteration stopped when the parent gene of the current group matched none of these highest-scoring genes.

\subsection{Merging of HSPs into hits}
HSPs were merged in two stages where the first combined non-overlapping HSPs, and the second combined the remaining HSPs. In the first stage, proceeding from highest to lowest bit score, HSPs were marked as ``disjoint'' if they did not overlap with any other HSP previously marked as disjoint. Although this greedy strategy did not necessarily yield the highest-scoring set of disjoint HSPs, it prioritized higher scoring HSPs. In the second stage, all disjoint HSPs were marked as ``compatible,'' and proceeding from highest to lowest bit score the remaining HSPs were marked as compatible if the overlap with any other compatible HSP was no more than 50\% of the length of either. The best hit for each query was chosen as the hit with the highest sum of bit scores from disjoint HSPs. The best hits were filtered by overlap and reciprocity criteria. The overlap criterion was applied first and required that 50\% of residues in the query were aligned in compatible HSPs. This excluded false positives from conserved domains embedded in larger non-homologous proteins by ensuring the hits spanned a sufficient fraction of the query and target sequences. The reciprocity criterion required each query-target pair had a corresponding hit where the roles were reversed, which ensured there was no ambiguity in which target was the best match for the query.

\subsection{Clustering by \textit{k}-clique percolation}
\textit{k}-clique percolation was implemented in two steps. In the first, maximal cliques were identified. In the second, a percolation graph was constructed by defining edges between cliques if they had \textit{k}-1 nodes in common. Clusters were the connected components of this second graph. The first step used the NetworkX implementation of a maximal clique algorithm. The second step used a modification of the NetworkX implementation of the \textit{k}-clique community algorithm. The NetworkX implementation exhaustively finds all edges in the percolation graph. Since joining a \textit{k}-clique community only requires that a clique has a single edge connecting it to that a community, this approach was needlessly expensive for large graphs. The custom implementation instead used a progressive approach where each clique was checked against a list of known communities, merging communities as necessary in each step.

The hit graph was sparse, so these algorithms were efficient when applied to its individual connected components. However, some components had a structure with many maximal cliques, which dramatically slowed the first or second step of the clique percolation algorithm. Thus, if either step exceeded 90 s, the process timed out, and the simpler \textit{k}-core algorithm was used instead. Out of over 10,000 connected components, only seven timed out, and many of those contained highly dense clusters of histone sequences.

\subsection{Addition of paralogs to orthologous groups}
The protein sequences for each annotation were searched against themselves with the same settings as for the inter-genome searches. The resulting output was processed identically except the HSPs were not filtered using the best gene criterion. Thus, all HSPs for each query were merged into hits. The best hit for each query and target gene was chosen as the hit with the highest sum of bit scores from disjoint HSPs. (Grouping by target gene ensured only the highest-scoring isoform was selected.) Query-target pairs whose hits exceeded the maximum bit score for all inter-genome hits associated with that query and passed the overlap and reciprocity filters were designated as paralogous pairs. The orthologous groups were supplemented with paralogs by adding the paired sequences for each of the original members of the orthologous group.

\subsection{Initial alignment and selection of representative sequences}
The sequences in each orthologous group were aligned using MAFFT 7.490 with the following settings: -{}-globalpair -{}-maxiterate 1000 -{}-thread 1 -{}-anysymbol -{}-allowshift -{}-leavegappyregion -{}-unalignlevel 0.4~\cite{Katoh2013}. Representative sequences for each gene were selected by maximum likelihood according to binary profiles constructed from these alignments. First each sequence was coded into gap and non-gap symbols. The sequences were grouped by gene, and for each group and position if at least one sequence was aligned in the group, the group contributed one count for the non-gap symbol to the profile at that position. Otherwise, the group contributed a count for the gap symbol at that position. To account for the phylogenetic dependencies between sequences, the counts were weighted according to a Gaussian process over the GTR2 consensus tree described in the section on inferring species trees~\cite{Altschul1989}. If a species had multiple genes in the orthologous group, the species weight was divided evenly among them. Each coded sequence was scored according to this profile, and the maximum likelihood sequence for each gene was selected as its representative. By assigning a non-gap count to groups and positions where at least one sequence was aligned, the profile prioritized the selection of sequences with the fewest gaps that best matched the consensus alignment. Since this scheme can cause a sequence to score negative infinity if it has a gap at a position where every group has at least one aligned sequence, the profile was initialized with a pseudocount of 0.005 for the gap and non-gap symbols at each position.

\subsection{Alignment refinement}
The representative sequences in the single copy orthologous groups were aligned with the same settings as described in the previous section except \textit{a\textsubscript{max}} was set to 0.7. A binary profile was created from the alignment using Gaussian process sequence weighting as described in the section on selecting representative sequences. (Because the orthologous groups were single copy and contained only representative sequences, each sequence received the full weight associated with its species.) The binary profile was converted into a binary mask by identifying where the weighted fraction of non-gap symbols exceeded 0.5. The binary mask was closed with a structuring element of size three, and highly conserved regions were identified as the contiguous intervals of this closed mask with a minimum length of 10. Diverged regions were taken as the complement of the highly conserved regions. For each diverged region, the corresponding segments of the sequences in the initial alignment were extracted and aligned with \textit{a\textsubscript{max}} set to 0.4. The resulting sub-alignments were stitched into the initial alignment.

\subsection{Alignment curation}
The alignments were coded into gap and non-gap symbols to simplify the emission distributions. The ``insertion'' phylo-HMM was composed of the four hidden states described in the main text. The emission distributions for each consisted of two components which modeled the gap pattern and the propensity for those patterns to remain constant (``gap stickiness''), respectively. The first component was a two-state Markov process which was in turn composed of two subprocess. The first was a phylogenetic process on the on the GTR2 consensus tree described in the section on inferring species trees, and the second was jump process at the tips. The second component was a beta-Bernoulli distribution on the number of symbols which were constant between subsequent columns. The ``missing data'' phylo-HMM was composed of two hidden states which were both parameterized with the same two-state, two component Markov process as the insertion phylo-HMM. However, the emission probabilities were calculated as the posterior probability of the observed symbol given the data rather than the probability of the data. Only the alignments of the single copy orthologous groups were curated, so each tip in the species tree corresponded to a single sequence in the alignment.

The likelihoods of phylogenetic trees were efficiently calculated with Felsenstein's pruning algorithm, and all HMM algorithms were implemented with custom code which is available as the package Homomorph on PyPI~\cite{Felsenstein1981}. The insertion phylo-HMM was trained on 47,387 manually labeled columns in 14 alignments, and the missing data phylo-HMM was trained on 67,001 manually labeled positions in 23 sequences in 11 unique alignments (Fig.~\ref{sfig:insertion_training}, Fig.~\ref{sfig:missing_training}). Because maximum-likelihood estimation of the model parameters yielded posterior decoding curves which toggled between hidden states too rapidly, the models were instead trained discriminatively~\cite{Krogh1999}. The difference, briefly, is maximum-likelihood estimation finds the parameters that best reproduce the observed distributions whereas discriminative training finds the parameters that minimize prediction error. Discriminatively trained models typically perform better in practice since real-world data are rarely fully described by the distribution specified by the model.

The posterior distributions over states were calculated for each alignment using the trained insertion phylo-HMM. Regions with a high probability of state 2 or 3 were candidates for trimming. However, because the probability of a state can change rapidly or gradually depending on the local context, a simple cutoff would not necessarily define the boundaries of these regions as the columns where the gap pattern changed most abruptly. Instead, the following algorithm was used. First, a high cutoff defined a ``seed'' region. The left and right endpoints of the seed were then expanded both inwards and outwards to define two intervals from which boundaries were selected. The outward expansion halted when the probability or its derivative was below two distinct thresholds, respectively. The inward expansion halted when the derivative was below a different threshold. The left and right boundaries were chosen as the columns in each interval with the maximum product between the derivative and the change in the gap profile between columns. The gap profile was calculated as the number of gaps in each column using Gaussian process sequence weighting as described in the section on selecting representative sequences. By combining where the model’s confidence changed rapidly with the observed change in the gap pattern, this method generally selected reasonable boundaries.

 States 2 and 3 have distinct characteristics which required different trimming strategies. Regions with a high probability of state 3 were handled first. Because the long poorly supported segments in state 3 regions were sometimes aligned to highly conserved columns or short segments in other sequences, trimming columns entirely would remove these segments from the other sequences even if they would not qualify as long and poorly supported themselves. Thus, regions with high state 3 probabilities were trimmed at the level of individual sequences rather than entire columns using the following method. First, the probability of state 3 for columns with a gap profile value less than or equal to 0.1 was set to 0 to break long poorly supported segments aligned to highly conserved columns into separate regions. Regions were defined with the previously described algorithm using high and low cutoffs of 0.75 and 0.01, respectively. The outer and inner derivative cutoffs were both 0.001. The mean number of non-gap symbols in a region was calculated using Gaussian process sequence weighting as described in the section on selecting representative sequences. (The sequences with the five most non-gap symbols were also excluded to not bias the estimate with long poorly supported segments.) The final mean $\mu$ was taken as the minimum of this value and two. A cutoff \textit{k}, derived from a geometric model of the number of non-gap symbols and a significance level $\alpha$, was calculated using the equation $k = \log(\alpha) / \log(1 - p) - 1$ where $p = \frac{1}{\mu + 1}$ and $\alpha = 0.01$. Any sequence whose number of non-gap symbols in the region equaled or exceeded this value was trimmed by replacing all non-gap symbols with gaps.

To trim the remaining state 2 regions, the posterior probability of state 2 was added to a modified state 3 probability which was set to zero for any state 3 regions identified in the previous step. This ensured that any regions which were intermediate between state 2 and 3 were included. Regions were defined from this combined probability using the algorithm described previously except with a high probability cutoff of 0.9 instead of 0.75. The posterior probabilities from the missing data phylo-HMM were converted into state assignments using a similar method. However, the initial seeds were defined with a cutoff of 0.75, and the seeds were expanded outward to the first non-gap symbol or until the posterior probability of the ``missing data'' state was below 0.05. These assignments, which are available in the supplementary data, can be used to filter segments or entire sequences from downstream analyses.

\subsection{Inference of species trees}
The orthology inference pipeline was first repeated with the outgroup species \textit{Scaptodrosophila lebanonensis}. Orthologous groups with one sequence for each species were aligned, and 100 meta-alignments were constructed by randomly sampling 10,000 columns from these 9,435 alignments. (The alignments were not refined before sampling.) To determine the effect of invariant columns and gaps, two sampling strategies were used where invariant columns were allowed or disallowed and the maximum fraction of gaps was set at 0, 50, and 100\%. Their combination yielded six different sets of meta-alignments. A tree was fit to each meta-alignment with the LG substitution model~\cite{Le2008}, four discrete gamma rate categories~\cite{Yang1994}, and optimized state frequencies using IQ-TREE 1.6.12~\cite{Nguyen2014}. If the sampling strategy allowed invariant columns, an invariant rate category was included. The resulting trees from each set were merged into a majority consensus tree (Fig.~\ref{sfig:trees_LG}). All figures are derived from the maximum 50\% gap fraction meta-alignment set unless otherwise noted.

To fit trees using the GTR model of nucleotide substitution, the protein alignments were converted to nucleotide alignments using the corresponding coding sequences in the genome annotations. Some protein sequences were ``low quality,'' meaning their coding sequences contained frameshifts, premature stop codons, or other errors even though they were strong hits to known protein-coding genes. The NCBI annotation pipeline corrects some of these defects in the protein sequences, which can complicate a simple ``reverse translation'' of the alignment. After rejecting alignments where the expected translation from a coding sequence differed from its corresponding protein sequence, 3,425 alignments remained. Consensus tree were derived from meta-alignments sampled from these alignments using the approach described previously except the GTR model was used in place of the LG model.

To fit trees using the two-state GTR model of substitution, the protein alignments were first coded into gap or non-gap symbols. As before, 100 meta-alignments were constructed from these coded alignments for each sampling strategy. In this case, only the presence of invariant columns was varied, yielding two sets of meta-alignments. Trees were fit using the GTR2 model with no rate categories. An invariant category, however, was included if invariant columns were allowed. Since the bootstrap confidences were sometimes lower than 50\%, the resulting trees from each set were merged into a loose consensus tree to prevent multifurcations (Fig.~\ref{sfig:trees_GTR}).

\subsection{Code and data availability}
\begin{sloppypar}
The code used to produce the results and analyses is available at \url{https://github.com/marcsingleton/orthology_inference2023}. HMM algorithms were implemented in the standalone package Homomorph which is available at \url{https://github.com/marcsingleton/homomorph} and on the Python Package Index (PyPI). The following Python libraries were used: matplotlib~\cite{Hunter2007}, NumPy~\cite{Harris2020}, pandas~\cite{McKinney2010}, and SciPy~\cite{Virtanen2020}. Relevant output files are available in the supporting information. There are no primary data associated with this manuscript. All primary data are available from publicly accessible sources described in their corresponding sections.
\end{sloppypar}
